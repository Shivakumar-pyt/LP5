{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc58f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1fb0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/hp/Desktop/LP5_DL/Boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d37eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe7d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = housing_data.drop(['Unnamed: 15','Unnamed: 16'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbac068a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT. MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  CAT. MEDV  \n",
       "0       15.3  396.90   4.98  24.0          0  \n",
       "1       17.8  396.90   9.14  21.6          0  \n",
       "2       17.8  392.83   4.03  34.7          1  \n",
       "3       18.7  394.63   2.94  33.4          1  \n",
       "4       18.7  396.90   5.33  36.2          1  \n",
       "..       ...     ...    ...   ...        ...  \n",
       "501     21.0  391.99   9.67  22.4          0  \n",
       "502     21.0  396.90   9.08  20.6          0  \n",
       "503     21.0  396.90   5.64  23.9          0  \n",
       "504     21.0  393.45   6.48  22.0          0  \n",
       "505     21.0  396.90   7.88  11.9          0  \n",
       "\n",
       "[506 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c6ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(housing_data.drop(['CAT. MEDV'],axis=1),housing_data['CAT. MEDV'],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61429a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd33323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb33d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783afec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b41d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128,input_shape=(14,), activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8a4458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 2s 37ms/step - loss: 0.1346 - mae: 0.2726 - val_loss: 0.0495 - val_mae: 0.1973\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0432 - mae: 0.1596 - val_loss: 0.0379 - val_mae: 0.1617\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0321 - mae: 0.1298 - val_loss: 0.0303 - val_mae: 0.1317\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0262 - mae: 0.1145 - val_loss: 0.0322 - val_mae: 0.1463\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0236 - mae: 0.1042 - val_loss: 0.0360 - val_mae: 0.1491\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0216 - mae: 0.0975 - val_loss: 0.0331 - val_mae: 0.1324\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0196 - mae: 0.0946 - val_loss: 0.0294 - val_mae: 0.1320\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0189 - mae: 0.0882 - val_loss: 0.0323 - val_mae: 0.1327\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0183 - mae: 0.0882 - val_loss: 0.0313 - val_mae: 0.1176\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0173 - mae: 0.0845 - val_loss: 0.0292 - val_mae: 0.1220\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0172 - mae: 0.0905 - val_loss: 0.0302 - val_mae: 0.1126\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0152 - mae: 0.0818 - val_loss: 0.0303 - val_mae: 0.1257\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0141 - mae: 0.0747 - val_loss: 0.0284 - val_mae: 0.1202\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0715 - val_loss: 0.0271 - val_mae: 0.1125\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0128 - mae: 0.0702 - val_loss: 0.0230 - val_mae: 0.1033\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0666 - val_loss: 0.0257 - val_mae: 0.1100\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0159 - mae: 0.0791 - val_loss: 0.0362 - val_mae: 0.1236\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0146 - mae: 0.0811 - val_loss: 0.0226 - val_mae: 0.1056\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.0686 - val_loss: 0.0295 - val_mae: 0.1198\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0111 - mae: 0.0660 - val_loss: 0.0305 - val_mae: 0.1104\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.0635 - val_loss: 0.0225 - val_mae: 0.0912\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0563 - val_loss: 0.0241 - val_mae: 0.1089\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0091 - mae: 0.0579 - val_loss: 0.0259 - val_mae: 0.1019\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0560 - val_loss: 0.0214 - val_mae: 0.0916\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0078 - mae: 0.0509 - val_loss: 0.0204 - val_mae: 0.0949\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0526 - val_loss: 0.0220 - val_mae: 0.0931\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0525 - val_loss: 0.0203 - val_mae: 0.0866\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0548 - val_loss: 0.0207 - val_mae: 0.0824\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0080 - mae: 0.0537 - val_loss: 0.0272 - val_mae: 0.1014\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0072 - mae: 0.0533 - val_loss: 0.0203 - val_mae: 0.0916\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0519 - val_loss: 0.0193 - val_mae: 0.0988\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0079 - mae: 0.0547 - val_loss: 0.0229 - val_mae: 0.0928\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0478 - val_loss: 0.0223 - val_mae: 0.0896\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0469 - val_loss: 0.0223 - val_mae: 0.0882\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0444 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0056 - mae: 0.0466 - val_loss: 0.0202 - val_mae: 0.0925\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - mae: 0.0462 - val_loss: 0.0169 - val_mae: 0.0783\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0390 - val_loss: 0.0227 - val_mae: 0.0921\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0396 - val_loss: 0.0149 - val_mae: 0.0768\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0347 - val_loss: 0.0262 - val_mae: 0.0953\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0380 - val_loss: 0.0163 - val_mae: 0.0774\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0336 - val_loss: 0.0186 - val_mae: 0.0795\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0335 - val_loss: 0.0177 - val_mae: 0.0860\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0372 - val_loss: 0.0204 - val_mae: 0.0849\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0336 - val_loss: 0.0185 - val_mae: 0.0764\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0355 - val_loss: 0.0208 - val_mae: 0.0908\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0519 - val_loss: 0.0201 - val_mae: 0.0868\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0480 - val_loss: 0.0181 - val_mae: 0.0773\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0442 - val_loss: 0.0158 - val_mae: 0.0837\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0439 - val_loss: 0.0201 - val_mae: 0.0885\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0385 - val_loss: 0.0146 - val_mae: 0.0684\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0033 - mae: 0.0330 - val_loss: 0.0187 - val_mae: 0.0792\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0030 - mae: 0.0289 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - mae: 0.0285 - val_loss: 0.0158 - val_mae: 0.0701\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0028 - mae: 0.0286 - val_loss: 0.0200 - val_mae: 0.0867\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0276 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0027 - mae: 0.0275 - val_loss: 0.0191 - val_mae: 0.0850\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0369 - val_loss: 0.0214 - val_mae: 0.0989\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0514 - val_loss: 0.0191 - val_mae: 0.0847\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0398 - val_loss: 0.0180 - val_mae: 0.0864\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0417 - val_loss: 0.0186 - val_mae: 0.0797\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0384 - val_loss: 0.0208 - val_mae: 0.0863\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0034 - mae: 0.0354 - val_loss: 0.0171 - val_mae: 0.0796\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0377 - val_loss: 0.0216 - val_mae: 0.0893\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0407 - val_loss: 0.0148 - val_mae: 0.0697\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0031 - mae: 0.0370 - val_loss: 0.0199 - val_mae: 0.0880\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0028 - mae: 0.0321 - val_loss: 0.0200 - val_mae: 0.0863\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0030 - mae: 0.0311 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0028 - mae: 0.0313 - val_loss: 0.0178 - val_mae: 0.0790\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0024 - mae: 0.0283 - val_loss: 0.0157 - val_mae: 0.0738\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0022 - mae: 0.0262 - val_loss: 0.0178 - val_mae: 0.0795\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0236 - val_loss: 0.0186 - val_mae: 0.0802\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0232 - val_loss: 0.0165 - val_mae: 0.0723\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0020 - mae: 0.0260 - val_loss: 0.0185 - val_mae: 0.0821\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0251 - val_loss: 0.0175 - val_mae: 0.0796\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0017 - mae: 0.0219 - val_loss: 0.0186 - val_mae: 0.0823\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0017 - mae: 0.0208 - val_loss: 0.0190 - val_mae: 0.0844\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0018 - mae: 0.0231 - val_loss: 0.0191 - val_mae: 0.0851\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0017 - mae: 0.0216 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0242 - val_loss: 0.0196 - val_mae: 0.0875\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0272 - val_loss: 0.0182 - val_mae: 0.0827\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0202 - val_mae: 0.0908\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0022 - mae: 0.0295 - val_loss: 0.0206 - val_mae: 0.0889\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0018 - mae: 0.0254 - val_loss: 0.0167 - val_mae: 0.0759\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0021 - mae: 0.0291 - val_loss: 0.0191 - val_mae: 0.0821\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0026 - mae: 0.0326 - val_loss: 0.0205 - val_mae: 0.0838\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0023 - mae: 0.0297 - val_loss: 0.0203 - val_mae: 0.0871\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0016 - mae: 0.0250 - val_loss: 0.0229 - val_mae: 0.0927\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0230 - val_loss: 0.0194 - val_mae: 0.0798\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0208 - val_loss: 0.0187 - val_mae: 0.0779\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 0.0196 - val_mae: 0.0863\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - mae: 0.0217 - val_loss: 0.0217 - val_mae: 0.0885\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 0.0207 - val_mae: 0.0847\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 0.0215 - val_mae: 0.0885\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 0.0193 - val_mae: 0.0794\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.5831e-04 - mae: 0.0177 - val_loss: 0.0220 - val_mae: 0.0905\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0010 - mae: 0.0176 - val_loss: 0.0192 - val_mae: 0.0781\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.8880e-04 - mae: 0.0181 - val_loss: 0.0225 - val_mae: 0.0866\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 0.0222 - val_mae: 0.0919\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 0.0215 - val_mae: 0.0884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e78442fd90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71357418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "706ef46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0260 - mae: 0.0887\n"
     ]
    }
   ],
   "source": [
    "prediction = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a96e986b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02602703869342804, 0.08869648724794388]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb4e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
